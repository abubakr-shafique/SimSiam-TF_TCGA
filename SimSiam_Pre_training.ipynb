{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sayakpaul/SimSiam-TF/blob/main/SimSiam_Pre_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3OQSgi4A8qI"
   },
   "source": [
    "A minimal implementation of **SimSiam** as proposed in [Exploring Simple Siamese Representation Learning](https://arxiv.org/pdf/2011.10566.pdf) by Xinlei Chen and Kaiming He. The objective of this notebook is to demonstrate the workflow of SimSiam and NOT to implement it note to note and at the same time I will try not to miss out on the major bits discussed in the paper. For that matter, I'll be using the Flowers dataset. \n",
    "\n",
    "Following depicts the workflow of SimSiam - \n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.ibb.co/37pNQTP/image.png\" width=550></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqSmdKq1DXdw",
    "outputId": "ce07b623-0cb2-4d5d-ee7d-997325cc1f4a"
   },
   "outputs": [],
   "source": [
    "#!pip install -U -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "__OnMx5CA4OB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HcAlVdqoB1Ik"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#tf.random.set_seed(666)\n",
    "#np.random.seed(666)\n",
    "\n",
    "#tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWNjwy4aB0S4",
    "outputId": "342595e2-a41e-4eb7-950b-5bbcf20aa16b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxDHbKMxCgq5",
    "outputId": "ade152a1-544e-4093-9ba3-2866a2cffa7e"
   },
   "outputs": [],
   "source": [
    "## Gather Flowers dataset\n",
    "#train_ds, validation_ds = tfds.load(\n",
    "#    \"tf_flowers\",\n",
    "#    split=[\"train[:85%]\", \"train[85%:]\"]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5247 files belonging to 4 classes.\n",
      "Found 5247 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_one = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'TCGA_Data/train1/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 16,\n",
    "    image_size = (224, 224),\n",
    ")\n",
    "\n",
    "dataset_two = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'TCGA_Data/train2/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 16,\n",
    "    image_size = (224, 224),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnhfS83AC6g8"
   },
   "source": [
    "Note the augmentation pipeline is a bit different from the augmentations followed in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM69XILOTRJ9"
   },
   "source": [
    "The network architectures are based on the **Method (Baseline settings)** section of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPoeLlhwFyTh"
   },
   "source": [
    "## Encoder ($f$)\n",
    "\n",
    "This includes ResNet50 as a backbone and another MLP for projection. Note that I have reduced the architectures here leaving ResNet50 backbone intact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EUx5xZxKFJ-a"
   },
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "        weights=None, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = tf.keras.layers.Input((224, 224, 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    z = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    f = tf.keras.Model(inputs, z)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRvzAOIBSjoG"
   },
   "source": [
    "## Predictor ($h$)\n",
    "\n",
    "This includes an MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qtcNe7znSjCH"
   },
   "outputs": [],
   "source": [
    "def get_predictor():\n",
    "    inputs = tf.keras.layers.Input((2048, ))\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    p = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    h = tf.keras.Model(inputs, p)\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n5xwsFWJl7e",
    "outputId": "16328095-ca65-49c4-b1b1-c490181bea36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              4194304   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "=================================================================\n",
      "Total params: 31,986,560\n",
      "Trainable params: 31,929,344\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_encoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2mcoe9JJror",
    "outputId": "1a3ec7a6-88df-4d18-8f96-d628695f53e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 2048)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              1050624   \n",
      "=================================================================\n",
      "Total params: 2,101,248\n",
      "Trainable params: 2,100,224\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_predictor().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7gjLDPmKPNn"
   },
   "source": [
    "The authors have also provided PyTorch-like psuedocode in the paper (how cool!) - \n",
    "\n",
    "```python\n",
    "# f: backbone + projection mlp\n",
    "# h: prediction mlp\n",
    "for x in loader: # load a minibatch x with n samples\n",
    "    x1, x2 = aug(x), aug(x) # random augmentation\n",
    "    z1, z2 = f(x1), f(x2) # projections, n-by-d\n",
    "    p1, p2 = h(z1), h(z2) # predictions, n-by-d\n",
    "    L = D(p1, z2)/2 + D(p2, z1)/2 # loss\n",
    "    L.backward() # back-propagate\n",
    "    update(f, h) # SGD update\n",
    "\n",
    "def D(p, z): # negative cosine similarity\n",
    "    z = z.detach() # stop gradient\n",
    "    p = normalize(p, dim=1) # l2-normalize\n",
    "    z = normalize(z, dim=1) # l2-normalize\n",
    "    return -(p*z).sum(dim=1).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mU8zs96EJ3Bc"
   },
   "outputs": [],
   "source": [
    "def loss_func(p, z):\n",
    "    z = tf.stop_gradient(z)\n",
    "    p = tf.math.l2_normalize(p, axis=1)\n",
    "    z = tf.math.l2_normalize(z, axis=1)\n",
    "    return - tf.reduce_mean(tf.reduce_sum((p*z), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P4-yuvuZMT0n"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(ds_one, ds_two, f, h, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z1, z2 = f(ds_one), f(ds_two)\n",
    "        p1, p2 = h(z1), h(z2)\n",
    "        loss = loss_func(p1, z2)/2 + loss_func(p2, z1)/2\n",
    "    \n",
    "    learnable_params = f.trainable_variables + h.trainable_variables\n",
    "    gradients = tape.gradient(loss, learnable_params)\n",
    "    optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3jIbS4R4O8kY"
   },
   "outputs": [],
   "source": [
    "def train_simsiam(f, h, dataset_one, dataset_two, optimizer, epochs=100):\n",
    "    step_wise_loss = []\n",
    "    epoch_wise_loss = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for ds_one, ds_two in zip(dataset_one, dataset_two):\n",
    "            loss = train_step(ds_one, ds_two, f, h, optimizer)\n",
    "            step_wise_loss.append(loss)\n",
    "\n",
    "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
    "\n",
    "    return epoch_wise_loss, f, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ys3VkUqVP_3r",
    "outputId": "b6393ae7-09d5-4872-ed1e-53721353ab8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 1/50 [02:08<1:45:15, 128.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: -0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▌                                                              | 11/50 [18:32<1:04:05, 98.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 loss: -0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▍                                               | 21/50 [34:57<47:35, 98.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 loss: -0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▊                               | 31/50 [51:22<31:13, 98.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 loss: -0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▌              | 41/50 [1:07:49<14:47, 98.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 loss: -0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [1:22:37<00:00, 99.14s/it]\n"
     ]
    }
   ],
   "source": [
    "decay_steps = 500\n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=decay_steps)\n",
    "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn, momentum=0.6)\n",
    "\n",
    "f = get_encoder()\n",
    "h = get_predictor()\n",
    "\n",
    "epoch_wise_loss, f, h  = train_simsiam(f, h, dataset_one, dataset_two, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kiJx3y5EQ57_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_wise_loss)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_weights(\"projection_TCGA.h5\")\n",
    "h.save_weights(\"prediction_TCGA.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNhEd2EnuPKQjsGMvm+zE3l",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SimSiam_Pre-training.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
